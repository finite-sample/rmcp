#!/usr/bin/env python3
"""
Comprehensive error handling tests for RMCP.

Tests various error scenarios to ensure robust error handling:
- Invalid input data
- Missing parameters
- R execution errors
- Network/resource issues
- Edge cases
"""

import asyncio
import json
import sys
from pathlib import Path

import pytest

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from rmcp.core.server import create_server
from rmcp.registries.tools import register_tool_functions
from rmcp.tools.fileops import read_csv
from rmcp.tools.formula_builder import build_formula
from rmcp.tools.helpers import suggest_fix, validate_data
from rmcp.tools.regression import linear_model


@pytest.mark.asyncio
async def test_missing_required_parameters():
    """Test tools handle missing required parameters gracefully."""
    print("ğŸ§ª Testing missing required parameters...")

    server = create_server()
    register_tool_functions(server.tools, linear_model)

    # Test missing data parameter
    request = {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "tools/call",
        "params": {
            "name": "linear_model",
            "arguments": {
                "formula": "y ~ x"
                # Missing "data" parameter
            },
        },
    }

    try:
        response = await server.handle_request(request)

        # Should not crash, but should return error
        if "error" in response:
            print("âœ… Missing parameters handled gracefully")
            return True
        else:
            # Check if result contains error info
            result = json.loads(response["result"]["content"][0]["text"])
            if "error" in str(result).lower():
                print("âœ… Missing parameters detected and reported")
                return True
            else:
                print("âŒ Missing parameters not properly handled")
                return False

    except Exception as e:
        print(f"âŒ Unhandled exception for missing parameters: {e}")
        return False


@pytest.mark.asyncio
async def test_invalid_data_types():
    """Test tools handle invalid data types."""
    print("ğŸ§ª Testing invalid data types...")

    server = create_server()
    register_tool_functions(server.tools, linear_model)

    # Test with invalid data (string instead of dict)
    request = {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "tools/call",
        "params": {
            "name": "linear_model",
            "arguments": {"data": "this_should_be_a_dict", "formula": "y ~ x"},
        },
    }

    try:
        response = await server.handle_request(request)

        if "error" in response:
            print("âœ… Invalid data types handled gracefully")
            return True
        else:
            result = json.loads(response["result"]["content"][0]["text"])
            if "error" in str(result).lower():
                print("âœ… Invalid data types detected and reported")
                return True
            else:
                print("âŒ Invalid data types not properly handled")
                return False

    except Exception as e:
        print(f"âŒ Unhandled exception for invalid data types: {e}")
        return False


@pytest.mark.asyncio
async def test_empty_data():
    """Test tools handle empty datasets."""
    print("ğŸ§ª Testing empty data handling...")

    server = create_server()
    register_tool_functions(server.tools, linear_model)

    # Test with empty data
    request = {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "tools/call",
        "params": {
            "name": "linear_model",
            "arguments": {"data": {}, "formula": "y ~ x"},
        },
    }

    try:
        response = await server.handle_request(request)

        if "error" in response:
            print("âœ… Empty data handled gracefully")
            return True
        else:
            result = json.loads(response["result"]["content"][0]["text"])
            if "error" in str(result).lower() or "empty" in str(result).lower():
                print("âœ… Empty data detected and reported")
                return True
            else:
                print("âŒ Empty data not properly handled")
                return False

    except Exception as e:
        print(f"âŒ Unhandled exception for empty data: {e}")
        return False


@pytest.mark.asyncio
async def test_malformed_json_in_tools():
    """Test tools handle malformed data gracefully."""
    print("ğŸ§ª Testing malformed data handling...")

    server = create_server()
    register_tool_functions(server.tools, linear_model)

    # Test with malformed data structure
    request = {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "tools/call",
        "params": {
            "name": "linear_model",
            "arguments": {
                "data": {
                    "x": [1, 2, "not_a_number", 4],
                    "y": [1, 2, 3],  # Different length
                },
                "formula": "y ~ x",
            },
        },
    }

    try:
        response = await server.handle_request(request)

        if "error" in response:
            print("âœ… Malformed data handled gracefully")
            return True
        else:
            result = json.loads(response["result"]["content"][0]["text"])
            if "error" in str(result).lower():
                print("âœ… Malformed data detected and reported")
                return True
            else:
                print("âŒ Malformed data not properly handled")
                return False

    except Exception as e:
        print(f"âŒ Unhandled exception for malformed data: {e}")
        return False


@pytest.mark.asyncio
async def test_invalid_formulas():
    """Test formula validation handles invalid formulas."""
    print("ğŸ§ª Testing invalid formula handling...")

    server = create_server()
    register_tool_functions(server.tools, linear_model)

    # Test with invalid R formula syntax
    request = {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "tools/call",
        "params": {
            "name": "linear_model",
            "arguments": {
                "data": {"x": [1, 2, 3, 4, 5], "y": [2, 4, 6, 8, 10]},
                "formula": "invalid ~ ~ syntax error",
            },
        },
    }

    try:
        response = await server.handle_request(request)

        if "error" in response:
            print("âœ… Invalid formulas handled gracefully")
            return True
        else:
            result = json.loads(response["result"]["content"][0]["text"])
            if "error" in str(result).lower() or "formula" in str(result).lower():
                print("âœ… Invalid formulas detected and reported")
                return True
            else:
                print("âŒ Invalid formulas not properly handled")
                return False

    except Exception as e:
        print(f"âŒ Unhandled exception for invalid formulas: {e}")
        return False


@pytest.mark.asyncio
async def test_nonexistent_file_handling():
    """Test file operations handle missing files."""
    print("ğŸ§ª Testing nonexistent file handling...")

    server = create_server()
    register_tool_functions(server.tools, read_csv)

    # Test reading nonexistent file
    request = {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "tools/call",
        "params": {
            "name": "read_csv",
            "arguments": {"file_path": "/nonexistent/path/file.csv"},
        },
    }

    try:
        response = await server.handle_request(request)

        if "error" in response:
            print("âœ… Nonexistent files handled gracefully")
            return True
        else:
            result = json.loads(response["result"]["content"][0]["text"])
            if "error" in str(result).lower() or "not found" in str(result).lower():
                print("âœ… Nonexistent files detected and reported")
                return True
            else:
                print("âŒ Nonexistent files not properly handled")
                return False

    except Exception as e:
        print(f"âŒ Unhandled exception for nonexistent files: {e}")
        return False


@pytest.mark.asyncio
async def test_error_recovery_tool():
    """Test the error recovery tool handles various error types."""
    print("ğŸ§ª Testing error recovery tool...")

    server = create_server()
    register_tool_functions(server.tools, suggest_fix)

    # Test with common R error
    request = {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "tools/call",
        "params": {
            "name": "suggest_fix",
            "arguments": {
                "error_message": "there is no package called 'nonexistent_package'"
            },
        },
    }

    try:
        response = await server.handle_request(request)

        if "error" in response:
            print("âŒ Error recovery tool failed")
            return False
        else:
            result = json.loads(response["result"]["content"][0]["text"])
            if "error_type" in result and "suggestions" in result:
                print("âœ… Error recovery tool working properly")
                return True
            else:
                print("âŒ Error recovery tool not providing proper analysis")
                return False

    except Exception as e:
        print(f"âŒ Unhandled exception in error recovery: {e}")
        return False


@pytest.mark.asyncio
async def test_data_validation_edge_cases():
    """Test data validation with edge cases."""
    print("ğŸ§ª Testing data validation edge cases...")

    server = create_server()
    register_tool_functions(server.tools, validate_data)

    # Test with edge case data (all missing values)
    request = {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "tools/call",
        "params": {
            "name": "validate_data",
            "arguments": {
                "data": {
                    "x": [None, None, None],
                    "y": [float("inf"), -float("inf"), float("nan")],
                }
            },
        },
    }

    try:
        response = await server.handle_request(request)

        if "error" in response:
            print("âœ… Edge case data handled gracefully")
            return True
        else:
            result = json.loads(response["result"]["content"][0]["text"])
            if "issues" in result or "warnings" in result:
                print("âœ… Edge case data issues detected")
                return True
            else:
                print("âŒ Edge case data issues not detected")
                return False

    except Exception as e:
        print(f"âŒ Unhandled exception in data validation: {e}")
        return False


@pytest.mark.asyncio
async def test_natural_language_formula_errors():
    """Test formula builder with ambiguous/invalid descriptions."""
    print("ğŸ§ª Testing natural language formula error handling...")

    server = create_server()
    register_tool_functions(server.tools, build_formula)

    # Test with very ambiguous description
    request = {
        "jsonrpc": "2.0",
        "id": 1,
        "method": "tools/call",
        "params": {
            "name": "build_formula",
            "arguments": {"description": "something something random words"},
        },
    }

    try:
        response = await server.handle_request(request)

        if "error" in response:
            print("âœ… Ambiguous descriptions handled gracefully")
            return True
        else:
            result = json.loads(response["result"]["content"][0]["text"])
            if "confidence" in result and result.get("confidence", 1.0) < 0.5:
                print("âœ… Low confidence formulas flagged")
                return True
            else:
                print("âš ï¸  Ambiguous descriptions accepted (may be ok)")
                return True  # This might be acceptable behavior

    except Exception as e:
        print(f"âŒ Unhandled exception in formula building: {e}")
        return False


async def main():
    """Run all error handling tests."""
    print("ğŸ”¥ RMCP Error Handling Test Suite")
    print("=" * 50)

    tests = [
        ("Missing Required Parameters", test_missing_required_parameters),
        ("Invalid Data Types", test_invalid_data_types),
        ("Empty Data Handling", test_empty_data),
        ("Malformed Data", test_malformed_json_in_tools),
        ("Invalid Formulas", test_invalid_formulas),
        ("Nonexistent File Handling", test_nonexistent_file_handling),
        ("Error Recovery Tool", test_error_recovery_tool),
        ("Data Validation Edge Cases", test_data_validation_edge_cases),
        ("Natural Language Formula Errors", test_natural_language_formula_errors),
    ]

    passed = 0
    total = len(tests)

    for test_name, test_func in tests:
        print(f"\nğŸ“‹ {test_name}:")
        print("-" * 40)
        try:
            if await test_func():
                passed += 1
        except Exception as e:
            print(f"âŒ Test failed with exception: {e}")

    print(f"\nğŸ¯ Error Handling Test Results:")
    print("=" * 50)
    print(f"âœ… Passed: {passed}/{total} ({passed/total*100:.1f}%)")

    if passed == total:
        print("ğŸ‰ All error handling tests passed!")
        print("ğŸ›¡ï¸  RMCP error handling is robust")
    elif passed >= total * 0.8:
        print("âœ¨ Most error handling tests passed")
        print(f"âš ï¸  {total - passed} test(s) need attention")
    else:
        print("âš ï¸  Multiple error handling failures")
        print("ğŸ”§ Error handling needs improvement")

    return passed == total


if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"\nğŸ’¥ Test suite failed: {e}")
        sys.exit(1)
